#!/usr/bin/env ruby
#
# Copyright (C) 2014-2015 Droonga Project
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License version 2.1 as published by the Free Software Foundation.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA

require "slop"
require "json"
require "pathname"
require "socket"
require "coolio"

require "droonga/engine/version"
require "droonga/path"
require "droonga/node_name"
require "droonga/node_role"
require "droonga/catalog/dataset"
require "droonga/catalog/fetcher"
require "droonga/catalog/loader"
require "droonga/safe_file_writer"
require "droonga/data_absorber_client"
require "droonga/serf"

module Droonga
  class JoinCommand
    class MissingRequiredParameter < StandardError
    end

    def run
      @loop = Coolio::Loop.default

      parse_options
      trap_signals

      puts "Start to join a new node #{joining_node.host}"
      puts "       to the cluster of #{source_node.host}"
      puts "                     via #{@options["receiver-host"]} (this host)"
      puts "    port    = #{joining_node.port}"
      puts "    tag     = #{joining_node.tag}"
      puts "    dataset = #{dataset}"
      puts ""

      if should_copy? and not absorber.empty_destination?
        $stderr.puts("Error: The joining node's dataset #{dataset} is not empty.")
        $stderr.puts("       You must clear all data of the node before joining.")
        return false
      end

      puts "Source Cluster ID: #{source_cluster_id}"
      puts ""

      begin
        set_joining_node_role
        do_join
        register_to_existing_nodes
        set_source_node_role
        if should_copy?
          successed = copy_data
          unless successed
            do_cancel
            return false
          end
        end
        set_effective_message_timestamp
        reset_source_node_role
        reset_joining_node_role
        puts("Done.")
        true
      rescue Exception => exception
        puts("Unexpected exception: #{exception.message}")
        puts(exception.backtrace.join("\n"))
        do_cancel
        false
      end
    end

    private
    def parse_options
      options = Slop.parse(:help => true) do |option|
        option.on("no-copy", "Don't copy data from the source cluster.",
                  :default => false)

        option.separator("Target:")
        option.on(:host=,
                  "Host name of the new node to be joined.",
                  :required => true)
        option.on("replica-source-host=",
                  "Host name of the soruce node in the cluster to be connected.",
                  :required => true)

        option.on(:port=,
                  "Port number of the source cluster to be connected.",
                  :as => Integer,
                  :default => NodeName::DEFAULT_PORT)
        option.on(:tag=,
                  "Tag name of the soruce cluster to be connected.",
                  :default => NodeName::DEFAULT_TAG)
        option.on(:dataset=,
                  "Dataset name of for the node to be joined.",
                  :default => Catalog::Dataset::DEFAULT_NAME)

        option.separator("Connections:")
        option.on("receiver-host=",
                  "Host name of this host.",
                  :default => Socket.gethostname)

        option.separator("Miscellaneous:")
        option.on("records-per-second=",
                  "Maximum number of records per second to be copied. " +
                    "'#{Client::RateLimiter::NO_LIMIT}' means no limit.",
                  :as => Integer,
                  :default => DataAbsorberClient::DEFAULT_MESSAGES_PER_SECOND)
        option.on("progress-interval-seconds=",
                  "Interval seconds to report progress.",
                  :as => Integer,
                  :default => DataAbsorberClient::DEFAULT_PROGRESS_INTERVAL_SECONDS)
        option.on(:verbose, "Output details for internal operations.",
                  :default => false)
      end
      @options = options
    rescue Slop::MissingOptionError => error
      $stderr.puts(error)
      raise MissingRequiredParameter.new
    end

    def dataset
      @options[:dataset]
    end

    def should_copy?
      not @options["no-copy"]
    end

    def joining_node
      @joining_node ||= NodeName.new(:host => @options[:host],
                                     :port => @options[:port],
                                     :tag  => @options[:tag])
    end

    def source_node
      @source_node ||= NodeName.new(:host => @options["replica-source-host"],
                                    :port => @options[:port],
                                    :tag  => @options[:tag])
    end

    def source_node_serf
      @source_node_serf ||= Serf.new(source_node.to_s,
                                     :verbose => @options.verbose)
    end

    def joining_node_serf
      @joining_node_serf ||= Serf.new(joining_node.to_s,
                                      :verbose => @options.verbose)
    end

    def source_cluster_id
      source_catalog.cluster_id
    end

    def source_catalog
      @source_catalog ||= parse_source_catalog
    end

    def parse_source_catalog
      loader = Catalog::Loader.new
      loader.parse(raw_source_catalog)
    end

    def raw_source_catalog
      @raw_source_catalog ||= fetch_source_catalog
    end

    def fetch_source_catalog
      fetcher = Catalog::Fetcher.new(:host          => source_node.host,
                                     :port          => source_node.port,
                                     :tag           => source_node.tag,
                                     :receiver_host => @options["receiver-host"])
      fetcher.fetch(:dataset => dataset)
    end

    def absorber
      @absorber ||= prepare_absorber
    end

    def prepare_absorber
      absorber_options = {
        :host    => joining_node.host,
        :port    => joining_node.port,
        :tag     => joining_node.tag,
        :dataset => dataset,

        :source_host    => source_node.host,
        :source_port    => source_node.port,
        :source_tag     => source_node.tag,
        :source_dataset => dataset,

        :receiver_host    => @options["receiver-host"],

        :messages_per_second => @options["records-per-second"],
        :progress_interval_seconds => @options["progress-interval-seconds"],

        :client_options   => {
          :backend => :coolio,
          :loop    => @loop,
        },
      }
      DataAbsorberClient.new(absorber_options)
    end

    def set_source_node_role
      if absorber.source_node_suspendable?
        puts("Changing role of the source node...")
        source_node_serf.do_and_wait_restart do
        source_node_serf.send_query("change_role",
                                    "node" => source_node.to_s,
                                    "role" => NodeRole::ABSORB_SOURCE)
        end
      end
      @source_node_role_changed = true
    end

    def set_joining_node_role
      puts("Changing role of the joining node...")
      joining_node_serf.do_and_wait_restart do
      joining_node_serf.send_query("change_role",
                                   "node" => joining_node.to_s,
                                   "role" => NodeRole::ABSORB_DESTINATION)
      end
      @joining_node_role_changed = true
    end

    def reset_source_node_role
      if absorber.source_node_suspendable?
        puts("Restoring role of the source node...")
        source_node_serf.do_and_wait_restart do
        source_node_serf.send_query("change_role",
                                    "node" => source_node.to_s,
                                    "role" => NodeRole::SERVICE_PROVIDER)
        end
      end
      @source_node_role_changed = false
    end

    def reset_joining_node_role
      puts("Restoring role of the joining node...")
      joining_node_serf.do_and_wait_restart do
      joining_node_serf.send_query("change_role",
                                   "node" => joining_node.to_s,
                                   "role" => NodeRole::SERVICE_PROVIDER)
      end
      @joining_node_role_changed = false
    end

    def do_join
      puts("Joining new replica to the cluster...")
      joining_node_serf.do_and_wait_restart do
      joining_node_serf.send_query("join",
                                   "node"    => joining_node.to_s,
                                   "type"    => "replica",
                                   "source"  => source_node.to_s,
                                   "dataset" => dataset)
      end
    end

    def copy_data
      puts("Copying data from the source node...")

      last_progress = nil
      absorber.run do |progress|
        if last_progress
          printf("%s", "#{" " * last_progress[:message].size}\r")
        end
        printf("%s", "#{progress[:message]}\r")
        last_progress = progress
      end
      @loop.run

      if absorber.error_message
        puts(absorber.error_message)
        return false
      end

      puts ""
      true
    end

    def set_effective_message_timestamp
      timestamp = source_node_serf.last_processed_message_timestamp
      unless timestamp
        $stderr.puts("Couldn't get the time stamp of " +
                       "the last processed message from the source node.")
        return false
      end
      if timestamp and not timestamp.empty?
        puts "The timestamp of the last processed message in the source node: #{timestamp}"
        puts "Setting effective message timestamp for the destination node..."
        response = joining_node_serf.send_query("accept_messages_newer_than",
                                                "node"      => joining_node.to_s,
                                                "timestamp" => timestamp)
      end
    end

    def register_to_existing_nodes
      puts("Register new node to existing hosts in the cluster...")
      source_node_serf.do_and_wait_restart do
      source_node_serf.send_query("add_replicas",
                                  "cluster_id" => source_cluster_id,
                                  "dataset"    => dataset,
                                  "hosts"      => [joining_node.host])
      end
      @node_registered = true
    end

    def unregister_from_existing_nodes
      puts("Unregister new node from existing hosts in the cluster...")
      source_node_serf.do_and_wait_restart do
      source_node_serf.send_query("remove_replicas",
                                  "cluster_id" => source_cluster_id,
                                  "dataset"    => dataset,
                                  "hosts"      => [joining_node.host])
      end
      @node_registered = false
    end

    def trap_signals
      trap(:TERM) do
        trap(:TERM, "DEFAULT")
        do_cancel
      end

      trap(:INT) do
        trap(:INT, "DEFAULT")
        do_cancel
      end

      trap(:QUIT) do
        trap(:QUIT, "DEFAULT")
        do_cancel
      end
    end

    def do_cancel
      #XXX we have to write more codes to cancel remote processes!
      unregister_from_existing_nodes if @node_registered
      reset_joining_node_role if @joining_node_role_changed
      reset_source_node_role if @source_node_role_changed
    end
  end
end

exit(Droonga::JoinCommand.new.run)
